<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link href="css/styles.css" rel="stylesheet">
      <title>Joseph Robi | Portfolio</title>
   </head>
   <body>
<!-- Page Header  -->
      <header class="page-header">
         <h1>Portfolio</h1>
      </header>
<!-- Main Content Area  -->
      <main>
         <!-- Module 1.1 Blog Post Starts Here-->
         <article>
            <header class="article-header">
               <h2>Module 1.1 Blog Post</h2>
            </header>
            <h3>Model-Based Systems Thinking</h3>
               <p>As digital systems continue to grow in scale and complexity, traditional approaches to design and problem solving aren't as effective as they once were. Modern systems are no longer isolated pieces of software or hardware; instead they are interconnected networks of components, stakeholders, constraints, and environments that continuously interact with one another. Cloud platforms, enterprise applications, transportation technologies, and large-scale information systems all demonstrate how difficult it is to predict outcomes when many elements operate together. In this context, systems thinking provides a way to understand complexity more effectively, while model-based systems engineering (MBSE) offers a practical method for managing it.</p>
               <p>This paper defines systems thinking in my own words, contrasts it with more traditional linear ways of thinking, and explains why a model-based approach is particularly well suited for designing and managing complex digital systems. Rather than treating systems as collections of independent parts, systems thinking and MBSE focus on relationships, interactions, and the broader context in which systems exist.</p>
            <h3>Defining Systems Thinking</h3>
               <p>Systems thinking can be defined as an approach to understanding systems by focusing on how components interact with one another within a defined boundary and how those interactions produce behavior over time. Rather than treating a system as a collection of independent parts, systems thinking emphasizes the relationships, dependencies, and feedback loops that connect those parts and shape overall system behavior. This approach encourages looking beyond individual components to identify patterns that influence how the system functions as a whole. From this perspective, the behavior of a system cannot always be fully explained by analyzing its parts separately, because many outcomes emerge from the way elements interact with one another within the broader context of the system.</p>
               <p>A key idea behind systems thinking is that systems exist within other systems. No system operates entirely on its own. Holt explains that the elements of a system are best understood in relation to each other and to other systems rather than in isolation (Holt & Weilkiens, 2023). This idea is especially relevant in digital environments, where software systems depend on infrastructure, external services, users, and organizational processes. A change made to one part of the system may lead to unexpected consequences elsewhere, even if the change seems minor.</p>
               <p>Another important aspect of systems thinking is the concept of boundaries. A system boundary defines what is considered part of the system and what lies outside it. Boundaries help establish scope, but they are not always fixed or universally agreed upon. Different stakeholders may perceive the boundary differently depending on their role and interests (Holt & Weilkiens, 2023). Systems thinking requires acknowledging these differences and making boundary decisions explicit so that assumptions are shared rather than implied. Overall, systems thinking is less about finding quick solutions and more about developing an accurate understanding of how a system behaves, why problems occur, and how changes may affect the system over time.</p>
            <h3>Traditional Linear Thinking</h3>
               <p>Traditional linear thinking approaches problems by breaking them down into smaller parts and addressing each part independently. This approach assumes clear and direct cause-and-effect relationships, where a specific action leads to a predictable and measurable outcome. Linear thinking works well in situations where systems are relatively simple, stable, and well understood, and where interactions between components are limited (Interaction Design Foundation, 2016). Many engineering tasks, classroom examples, and academic exercises rely on this approach because it is efficient, structured, and easy to manage.</p>
               <p>However, linear thinking struggles when applied to complex systems. In these environments, cause and effect are often separated by time, distance, or multiple layers of interaction, making outcomes harder to predict (Interaction Design Foundation, 2016). A change made today may not reveal its full impact until much later, and the final outcome may be shaped by factors that fall outside the original scope of the problem. Linear thinking tends to overlook these indirect effects because it focuses narrowly on individual components or immediate results rather than broader system behavior.</p>
               <p>Another limitation of linear thinking is its tendency toward local optimization. Teams may improve one part of a system without fully considering how that improvement affects the rest of the system (Interaction Design Foundation, 2016). For example, increasing processing speed in one service may create bottlenecks in another, or improving security controls may unintentionally reduce usability for end users. Without a broader view of the system and its interactions, well-intentioned changes can introduce new problems that were not anticipated during design.</p>
            <h3>How Systems Thinking Differs from Linear Thinking</h3>
               <p>Systems thinking differs from linear thinking in several fundamental ways. First, systems thinking prioritizes interactions over individual components. While linear thinking asks how a part functions on its own, systems thinking asks how that part interacts with other elements and contributes to overall system behavior. Holt emphasizes that interactions between system elements are just as important as the elements themselves (Holt & Weilkiens, 2023).</p>
               <p>Second, systems thinking recognizes that system behavior is often emergent. Emergent behavior refers to outcomes that arise from interactions among components rather than from any single component acting alone. In complex digital systems, issues including cascading failures, performance degradation, or security vulnerabilities often emerge from combinations of small decisions rather than a single obvious flaw.</p>
               <p>Third, systems thinking is inherently stakeholder-focused. Different stakeholders interact with the system in different ways and have different needs, goals, and perspectives. Holt describes stakeholders as roles rather than specific individuals, noting that a single person may occupy multiple stakeholder roles depending on the context (Holt & Weilkiens, 2023). Systems thinking encourages designers to consider these diverse perspectives early, reducing the risk of conflicts or unmet needs later in the system's life cycle. Finally, systems thinking is adaptive rather than static. It acknowledges that systems evolve over time and that understanding must be continuously updated as conditions change. This makes systems thinking particularly well suited to digital environments, where technologies, regulations, and user expectations change rapidly.</p>
            <h3>The Need for a Model-Based Approach</h3>
               <p>As systems grow more complex, relying solely on informal descriptions, disconnected documents, or individual expertise becomes risky. Model-based systems engineering addresses this challenge by using formal models to represent system structure, behavior, requirements, constraints, and relationships. These models serve as a shared source of truth that supports communication, analysis, and decision making.</p>
               <p>The applicability of MBSE becomes clear when considering the core elements of systems thinking. Holt discusses system elements, interfaces, stakeholders, boundaries, needs, and constraints as fundamental concepts in systems engineering (Holt & Weilkiens, 2023). MBSE provides a way to capture these concepts explicitly rather than leaving them implicit or scattered across multiple documents. For complex digital systems, this explicit representation is critical. Digital systems often involve numerous interfaces, both internal and external. Data flows, control signals, authentication mechanisms, and integration points must all work together reliably. A model-based approach allows teams to define and analyze these interfaces systematically, reducing the likelihood of misunderstandings or integration failures.</p>
            <h3>MBSE and Managing Complexity</h3>
               <p>One of the greatest advantages of MBSE is its ability to make complexity manageable. Rather than overwhelming teams with excessive detail, a well-designed model highlights what matters most at each level of abstraction (Singam & Carter, 2025). High-level models can focus on system goals and stakeholder needs, while more detailed models can address architecture, behavior, and interfaces. MBSE also supports consistency across different viewpoints. Complex systems are typically examined from multiple perspectives, such as functional, operational, technical, and organizational (Singam & Carter, 2025). Without a model-based approach, these perspectives are often documented separately, leading to inconsistencies. MBSE allows these views to be derived from a single underlying model, ensuring alignment across teams.</p>
               <p>Change management is another area where MBSE is particularly valuable. Digital systems are rarely static, and changes are inevitable. When requirements, constraints, or technologies change, a model can help identify which parts of the system are affected (Meißner et al., 2021). This makes it easier to assess impacts before changes are implemented, reducing the risk of unintended consequences.</p>
            <h3>Boundaries, Interfaces, and Stakeholders in MBSE</h3>
               <p>Boundaries play a central role in both systems thinking and MBSE. Defining system boundaries helps clarify scope, ownership, and responsibility. In digital systems, boundaries are often conceptual rather than physical, which can make them difficult to define clearly. MBSE supports boundary definition by explicitly modeling what is inside the system and what lies outside it. Interfaces occur wherever interactions cross system boundaries. Holt notes that identifying interfaces is essential for specifying and defining systems (Holt & Weilkiens, 2023). In digital environments, poorly defined interfaces are a common source of failure. MBSE helps teams document and analyze interfaces early, improving integration and reducing ambiguity.</p>
               <p>Stakeholders also benefit from a model-based approach. Because stakeholders view systems differently depending on their role, models can provide tailored views that address specific concerns without losing alignment with the overall system. This supports clearer communication and more informed decision making throughout the system life cycle.</p>
            <h3>MBSE as a Support Tool, Not a Replacement for Judgment</h3>
               <p>While MBSE offers many benefits, it is important to recognize its limitations. Models are simplifications of reality and must be maintained to remain useful. Poorly designed or outdated models can create false confidence rather than clarity. Holt emphasizes that systems engineering does not eliminate the need for intelligence and judgment, and practitioners should not blindly follow prescribed methods (Holt & Weilkiens, 2023). The value of MBSE is in how it is used. When applied thoughtfully it enhances understanding, communication, and analysis. When applied from a more mechanical perspective it can become a bureaucratic exercise. Effective use of MBSE requires selecting the right level of detail and focusing on aspects of the system that are most critical to success.</p>
            <h3>Conclusion</h3>
               <p>Systems thinking provides a framework for understanding complex systems by emphasizing relationships, interactions, boundaries, and stakeholder perspectives. Unlike traditional linear thinking, which assumes simple cause-and-effect relationships, systems thinking acknowledges that behavior often emerges from the interaction of many components over time. This perspective is essential for understanding modern digital systems, where complexity and interdependence are the norm.</p>
               <p>Model-based systems engineering complements systems thinking by offering a structured way to represent and manage complexity. By making system elements, interfaces, needs, constraints, and boundaries explicit, MBSE supports better communication, more informed decision making, and improved change management. Grounded in the core principles of systems engineering, a model-based approach helps teams design and evolve complex digital systems more effectively while remaining adaptable in a constantly changing environment.</p>
         <footer class="article-footer">
            <h3>Sources:</h3>
            <ol>
               <li>
                  Holt, J., &amp; Weilkiens, T. (2023).
                  <em>Systems engineering demystified: Apply modern, model-based systems engineering techniques to build complex systems</em> (2nd ed.).
                  Packt Publishing.
               </li>
               <li>
                  Interaction Design Foundation. (2016, November 26).
                  <em>What is linear thinking?</em>
                  <a href="https://www.interaction-design.org/literature/topics/linear-thinking">
                     https://www.interaction-design.org/literature/topics/linear-thinking
                  </a>
               </li>
               <li>
                  Singam, C., &amp; Carter, J. (2025, November 17).
                  <em>Model based systems engineering (MBSE)</em>.
                  Systems Engineering Body of Knowledge.
                  <a href="https://sebokwiki.org/wiki/Model-Based_Systems_Engineering_%28MBSE%29">
                     https://sebokwiki.org/wiki/Model-Based_Systems_Engineering_%28MBSE%29
                  </a>
               </li>
               <li>
                  Meißner, M., Jacobs, G., Jagla, P., &amp; Sprehe, J. (2021).
                  <em>Model based systems engineering as enabler for rapid engineering change management</em>.
                  <em>Procedia CIRP, 100</em>, 146–151.
                  <a href="https://doi.org/10.1016/j.procir.2021.05.010">
                     https://doi.org/10.1016/j.procir.2021.05.010
                  </a>
               </li>
            </ol>
         </footer>
         </article>

         <!-- Module 1.2 Blog Post Starts here -->
         <article>
            <header class="article-header">
               <h2>Module 1.2 Blog Post</h2>
            </header>
            <h3>Understanding the Systems Development Life Cycle</h3>
               <p>Digital systems do not get built once and then quietly “exist.” They launch, get used, patched, scaled, extended, and eventually replaced as conditions around them change. Even when a system feels stable from the outside, it is still being shaped by evolving user needs, emerging security threats, growing data volumes, shifting regulations, and rising expectations around performance, availability, and reliability. That constant pressure is why systems engineers emphasize life cycles. Life cycle thinking is not just a project management tool. It is a long-term mindset for designing systems that can endure real-world complexity long after development ends.</p>
               <p>In systems engineering terms, a life cycle describes how a system evolves through stages, while a life cycle model describes how those stages are executed and ordered (Holt & Weilkiens, 2023). This distinction matters because many projects share similar stages but follow very different execution patterns depending on uncertainty, risk, organizational constraints, and technical complexity. In this post, I define the systems development life cycle, describe the key characteristics, advantages, and drawbacks of linear, iterative, and incremental life cycle models, and reflect on why life cycle thinking is essential for the design, sustainability, and long-term evolution of modern digital systems.</p>
            <h3>Defining the Systems Development Life Cycle</h3>
               <p>The systems development life cycle, often called the SDLC, is the full progression a system goes through from its initial idea to its retirement. It is not limited to building and deploying software (Awati & Gillis, 2024). Instead, it captures the complete evolution of a system as it is conceived, developed, introduced, used, supported, and eventually replaced. When people describe a system as “done,” they are usually referring to a temporary milestone, such as a release or deployment. From a systems perspective, that moment is only a transition, not an ending. A system continues to evolve as it interacts with real users and operating environments (Holt & Weilkiens, 2023).</p>
               <p>Most digital systems move through similar life cycle phases. While terminology differs, the underlying pattern is consistent. Conception is where needs are defined. Stakeholders identify the problem, clarify goals, surface constraints, and determine what success looks like. In digital environments, this includes decisions about users, data, security, compliance, and performance expectations. Development is where potential solutions are explored and refined into a workable design and architecture. This includes decisions about components, interfaces, integrations, workflows, and how the system will be tested and deployed (Awati & Gillis, 2024). Even when “design” and “development” are separated, they still answer the same question: what are we building, and how should it behave?</p>
               <p>Production is where the system is constructed and validated. For digital systems, this often includes infrastructure setup, environment configuration, and monitoring, not just writing code (Holt & Weilkiens, 2023). The goal is to ensure the system works correctly and satisfies the original needs. Utilization is when the system begins serving real users. This is where assumptions are tested and real usage patterns appear. Data volumes grow, edge cases surface, and dependencies change. The system becomes part of a larger ecosystem. Support includes maintenance, security updates, performance tuning, monitoring, and incident response. For most digital systems, this is the longest phase and the one that determines long-term reliability and trust.</p>
               <p>Retirement is the planned decommissioning of the system. This often involves data migration, regulatory retention, shutting down integrations, and transitioning users (Holt & Weilkiens, 2023). When retirement is ignored, organizations become stuck with fragile legacy systems. These phases demonstrate why systems are not “finished” after launch. Real environments change continuously, and systems must evolve to remain useful and secure.</p>
            <h3>Life Cycle Models</h3>
               <p>A life cycle defines the stages a system passes through. A life cycle model describes how those stages are executed and ordered (Holt & Weilkiens, 2023). Linear, iterative, and incremental models represent different approaches to handling uncertainty and change.</p>
                  <h4>The Linear Life Cycle Model</h4>
                     <p>The linear model executes stages in a fixed, sequential order. Each phase is completed before the next begins, and progress moves forward in a straight line from conception to delivery. The classic example of this approach is the waterfall model, which has been widely used in both engineering and software development contexts. Its main advantage is clarity. Linear models are easy to plan, communicate, and govern because each stage has a clearly defined start and end point. They work best when requirements are stable, technologies are well understood, and the overall system scope is limited. In these situations, teams can move confidently from one stage to the next without needing to revisit earlier decisions.</p>
                     <p>However, the linear model assumes a level of certainty that many digital systems do not have. When requirements change late in the process, linear execution absorbs the cost through extensive rework. Another drawback is late feedback. Usability issues, performance limitations, or design flaws may remain hidden until deployment, when fixes are most expensive and disruptive. Holt and Weilkiens note that linear models are best suited to small, well-defined projects and not to large, complex systems where needs change frequently (Holt & Weilkiens, 2023).</p>
                  <h4>The Iterative Life Cycle Model</h4>
                     <p>The iterative model is built around repetition and continuous learning. Instead of a single pass through the stages, the team cycles through them multiple times, using each iteration to improve the system based on feedback and new insights. Each cycle produces a version of the system that can be evaluated, tested, and refined. Its greatest strength is feedback (Efimova, 2024). Iteration reduces the risk of building the wrong system because assumptions are tested early and often. It also supports adaptation, allowing the system to evolve as user needs, technologies, and expectations change. Iterative approaches are especially useful for complex digital systems where requirements are uncertain or still emerging. They align well with prototyping, usability testing, and continuous improvement practices that are common in modern digital environments.</p>
                     <p>The drawback is the need for discipline. Without clear goals, boundaries, and quality controls, iteration can become chaotic. Teams may rush releases, overlook long-term impacts, and accumulate technical debt. Holt and Weilkiens emphasize that model-based methods can still be applied in iterative environments to help manage complexity and improve communication among stakeholders (Holt & Weilkiens, 2023).</p>
                  <h4>The Incremental Life Cycle Model</h4>
                     <p>The incremental model delivers a system in pieces rather than all at once. Instead of a single final release, the system grows through multiple increments that add new functionality and capabilities over time. Each increment represents a step toward the fully realized system. Its primary advantage is early value. Users and organizations can begin benefiting from the system sooner, and overall project risk is reduced by introducing capability gradually rather than through a single large release.</p>
                     <p>Incremental approaches work well for long projects and for systems that can be decomposed into meaningful components or modules. They allow organizations to avoid disruptive “big bang” deployments and instead introduce change in a controlled and manageable way. However, not all systems can be broken into useful subsets. Integration across increments can also become complex and difficult to manage. Holt and Weilkiens note that incremental models are effective when partial capability is useful early, but unsuitable when the system cannot be meaningfully decomposed (Holt & Weilkiens, 2023).</p>
            <h3>Comparing the Models</h3> 
               <p>The key difference among these models is how they treat change. Linear approaches resist change by locking decisions early and assuming that most requirements can be defined in advance. Iterative approaches expect change and use repeated cycles to absorb new information, feedback, and shifting needs as the system evolves. Incremental approaches also expect growth, but they focus on delivering that growth in clearly defined stages through controlled releases that gradually expand system capability (Efimova, 2024).</p>
               <p>Risk is also managed differently across the three models. Linear models rely heavily on upfront planning and documentation, which can work well when uncertainty is low but can fail when assumptions prove incorrect. Iterative models reduce risk through early learning, frequent validation, and continuous refinement, allowing problems to surface before they become costly (Efimova, 2024). Incremental models reduce rollout risk by limiting the scope of each release, although they introduce their own challenges related to coordination, integration, and long-term consistency.</p>
               <p>Fit ultimately depends on context. Stable, small projects may suit linear execution because the requirements are unlikely to change and the scope is well understood. User-facing digital systems often benefit from iteration because user expectations, technologies, and competitive pressures evolve rapidly (Efimova, 2024). Large enterprise systems may benefit from incremental delivery to reduce disruption and allow organizations to adopt new capabilities gradually. In practice, many organizations blend these models. The goal is not to follow one model rigidly, but to choose an execution pattern that aligns with system complexity, organizational constraints, and the level of uncertainty involved.</p>  
            <h3>Life Cycle Thinking</h3>
               <p>Life cycle thinking matters because digital systems must survive long after launch. Security threats evolve, dependencies change, and compliance requirements continue to grow as regulations and industry standards shift. Systems that cannot be updated safely or consistently over time quickly become liabilities rather than assets. Scaling is another major challenge. As user bases expand, growth affects performance, data volume, reliability, and the complexity of support processes. These pressures usually emerge after deployment, not during initial development, which is why planning only for launch is never sufficient. User feedback also reshapes systems in important ways. Real usage reveals design gaps, unexpected behaviors, and limitations that are impossible to fully predict in advance (Holt & Weilkiens, 2023). Without a life cycle mindset that embraces ongoing change, systems become rigid, difficult to adapt, and increasingly irrelevant to users.</p>
               <p>Sustainability depends heavily on maintainability. Systems that are difficult to understand, modify, or extend drain organizational resources and slow innovation. Ignoring life cycle planning leads directly to technical debt, where short-term decisions turn into long-term burdens that limit future flexibility. Digital systems also depend on external technologies that have their own life cycles. When those technologies decline, become obsolete, or change unexpectedly, systems must adapt or risk failure. Life cycle thinking helps teams anticipate and manage these transitions rather than simply reacting to them when problems arise (Holt & Weilkiens, 2023).</p>
            <h3>Conclusion</h3>
               <p>The systems development life cycle describes how digital systems evolve from conception through development, deployment, utilization, support, and retirement. Life cycle models define how those stages are executed. The linear model offers simplicity but struggles with change. The iterative model supports learning and adaptation but requires discipline. The incremental model enables staged value delivery but depends on strong architecture and integration. For modern digital systems, life cycle thinking is essential. It allows teams to design systems that evolve rather than collapse under change. Systems that succeed over time are not the ones that launch once, but the ones built to grow, adapt, and endure.</p>
         <footer class="article-footer">
            <h3>Sources:</h3>
            <ol>
               <li>
                  Holt, J., &amp; Weilkiens, T. (2023).
                  <em>Systems engineering demystified: Apply modern, model-based systems engineering techniques to build complex systems</em> (2nd ed.).
                  Packt Publishing.
               </li>
               <li>
                  Awati, R., &amp; Gillis, A. S. (2024, September 23).
                  <em>What is systems development life cycle?</em>
                  TechTarget.
                  <a href="https://www.techtarget.com/searchsoftwarequality/definition/systems-development-life-cycle">
                     https://www.techtarget.com/searchsoftwarequality/definition/systems-development-life-cycle
                  </a>
               </li>
               <li>
                  Efimova, D. (2024, July 12).
                  <em>Comparison of SDLC models: How to choose the best for your project?</em>
                  EPAM.
                  <a href="https://startups.epam.com/blog/software-development-models-comparison">
                     https://startups.epam.com/blog/software-development-models-comparison
                  </a>
               </li>
            </ol>
         </footer>
         </article>
         <!-- Module 2.1 Blog Post Starts here -->
         <article>
            <header class="article-header">
               <h2>Module 2.1 Blog Post</h2>
            </header>
            <h3>Designing for People Means Designing for Minds</h3>
            <p>“Design for people” sounds like a slogan until you sit with what it actually implies. People do not interact with interfaces as purely neutral or perfectly rational users. They arrive with prior experiences, limited attention, imperfect memory, and goals that are shaped by stress, time pressure, and context. They also arrive with expectations about how things should work, because every product they've used before quietly trains them. Human-centered design treats these realities as core requirements rather than edge cases.</p>
            <p>That mindset is why I think human-centered design is less about making something look friendly and more about making something fit the way humans perceive, decide, and act. If the design fights perception, it will be overlooked. If it fights attention, it will be ignored. If it fights memory, it will become an afterthought. If it fights empathy, it will feel like the system was built for the organization instead of the person using it.</p>
            <h3>Human-Centered Design</h3>
            <p>Human-centered design is often described as “putting users first,” but that framing can be misleading because it can sound like a preference instead of a method. In practice, it is a structured approach to developing interactive systems by grounding decisions in an understanding of users, tasks, and environments, involving users directly, and iterating designs based on feedback until the solution reliably meets user requirements (International Organization for Standardization [ISO], 2019). That last point matters. Human-centered design is not simply listening to users once, then building whatever the team prefers. It is an ongoing loop where evidence continues to shape the product.</p>
            <p>The implication here with human-centered design is that usability and user experience do not “appear” at the end. They're outcomes of choices made earlier, especially choices about what problems the system is truly solving, for who, and under what real-world constraints. In other words, designing for people starts long before the UI, because the UI is only the visible layer of a bigger relationship between human goals and system behavior.</p>
            <h3>ISO 9241-210 and IDEO's Field Guide</h3>
            <p>ISO 9241-210 and IDEO's Field Guide both land on the same commitment: meaningful design requires a real understanding of the people affected by it. Where they differ is in how they frame the work and what they emphasize as “good practice.”</p>
            <p>ISO 9241-210 reads more like a professional standard (because it technically is one) and treats human-centered design as a process that can be planned, integrated into different development approaches, and executed with clear stages. The emphasis is on comprehensive understanding of context of use, formalizing user requirements so they are auditable, evaluating designs against those requirements, and iterating until the design solutions meet them (ISO, 2019). It also stresses that human-centered design is not the job of one role. It assumes interdisciplinary competencies and repeatedly brings the user or domain expert perspective into the project as an active duty, not a nice-to-have (ISO, 2019). That framing makes it easier to defend human-centered work in environments that demand traceability, accountability, and risk management.</p>
            <p>IDEO's Field Guide, by contrast, feels like a field manual for creative problem solving. Its language centers on belief, mindset, and practice: the conviction that problems are solvable, the habit of learning directly from people, the willingness to prototype, the expectation of early failure, and the continuous shift between diverging into many options and converging toward what is most desirable, feasible, and viable (IDEO.org, 2015). It outlines phases like Inspiration, Ideation, and Implementation, but it is honest that real projects are not linear and that the imperfect is normal (IDEO.org, 2015). ISO more so provides structure you can map to governance. IDEO more so provides momentum you can map to discovery.</p>
            <p>Taken together, they describe human-centered design as both disciplined and exploratory. ISO keeps teams anchored to context, requirements, and evaluation. IDEO keeps teams willing to learn, iterate, and make ideas tangible so that feedback can shape reality, not just theory. If ISO helps you prove that you designed responsibly, IDEO helps you keep designing when you do not yet know the answer.</p>
            <h3>Perception and Visual Hierarchy</h3>
            <p>A major reason human-centered design works is that it respects the difference between what designers intend users to see and what users actually notice. Perception is selective. Attention is limited. Visual hierarchy is the tool we use to guide both. Consider a simple example such as a checkout page with a large promo-code box placed above the “Place Order” button. The design may be technically correct, but perception will often treat that promo box as the next required step. Users pause, scan, and wonder whether they missed something. Some leave to search for a code. Others assume they cannot proceed without one. That is not a content problem. It is a hierarchy problem. The interface accidentally told users that discounts are the primary task, not completing the purchase.</p>
            <p>The same dynamic shows up in dashboards and business tools. If a screen presents ten equal-weight charts, equal-weight colors, and equal-weight typography, it effectively tells the user, “All of this is equally urgent.” But users do not have equal attention to give. They need the interface to do some of the sorting. Strong hierarchy does that by making the primary action visually dominant, by grouping related information, and by reducing competition for attention. When hierarchy is weak, users compensate by reading more, scanning longer, and making more guesses. That increases cognitive load and produces more errors, even if every element is technically accessible.</p>
            <p>This is where “designing for people” becomes concrete. People use shortcuts. They look for shapes and patterns. They trust what is prominent. They assume that what is familiar will behave in familiar ways. If your hierarchy is misaligned with user goals, your usability issues will not show up as broken features. They will show up as hesitation, repeated scanning, and abandonment.</p>
            <h3>How the Four UX Laws Support Human-Centered Decisions</h3>
            <p>The four UX laws often get presented as design trivia, but they are more useful when treated as explanations for why certain choices consistently succeed or fail. They connect perception, attention, and memory to measurable outcomes.</p>
            <p>Jakob's Law is the expectation engine. Users spend most of their time in other products, so they bring learned patterns into your interface (Chung, 2023). Designing for people means leveraging those patterns rather than demanding that users relearn basics. For example, if your navigation behaves differently from common conventions, the cost is not only confusion. The cost is attention. Users shift from goal-focused behavior to interface-focused behavior, and that mental mode switch is exhausting (Chung, 2023). Human-centered design does not eliminate innovation, but it chooses carefully where novelty is worth the learning burden and where familiarity is the more humane choice.</p>
            <p>Fitts's Law explains why usability is physical as well as cognitive. People do not just decide what to click (Budiu, 2022). They also have to acquire the target. Small, tightly packed buttons, especially near other dangerous actions, increase movement time and error rate. A common mistake is treating spacing and size as purely aesthetic. In reality, they shape effort and accuracy. If you want people to take the primary action, you make it easier to hit, not just easier to understand. If you want to prevent irreversible mistakes, you create separation and require intentionality. That is empathy expressed through geometry.</p>
            <p>Hick's Law is the attention tax. The more choices presented at once, the longer it takes to decide, especially when options are similar or poorly differentiated (Interaction Design Foundation, 2016). This shows up everywhere in digital systems: settings menus with dozens of toggles, onboarding flows that ask users to choose a plan before they understand value, or enterprise forms that present every field as mandatory up front. A human-centered approach respects that decision-making is work. It reduces the work by staging complexity, using progressive disclosure, and helping users recognize the best next step rather than forcing them to evaluate every possible step.</p>
            <p>Miller's Law, often summarized as limits on working memory, is the memory reality check (Uzegbu, 2024). People can only hold a small number of items in mind at once, and that capacity drops further when they are stressed, distracted, or unfamiliar with the domain. This is why chunking is not optional. It is why long, ungrouped forms feel overwhelming. It is why confirmation screens that repeat key details reduce anxiety. It is why showing a summary of what the user already selected prevents them from having to remember it. Designing for people means not treating memory as free storage. It means designing so that users can recognize information rather than recall it from scratch.</p>
            <p>When these laws are taken seriously, they stop being abstract. They become the rationale behind hierarchy, layout, interaction design, and even product scope. They also connect naturally to ISO and IDEO. ISO pushes you to ground decisions in user context and evaluate against requirements, which makes these laws testable. IDEO pushes you to prototype and learn quickly, which is how you discover where attention, memory, and expectation are breaking down in the real world.</p>
            <h3>Empathy, Human Factors and Real Outcomes</h3>
            <p>Empathy is sometimes framed as emotional warmth, but in design it is closer to disciplined perspective-taking. It is the habit of assuming that friction is more often a design problem than a user problem. It is also the habit of asking what conditions shape behavior. Is the user hurried? Are they on a small screen? Are they interrupted? Are they anxious about making an error? Those conditions change what “good usability” means.</p>
            <p>ISO emphasizes that desk research alone is insufficient, and that direct user involvement and feedback are required to iteratively refine solutions (ISO, 2019). IDEO frames empathy as a mindset and a practice, grounded in learning from people and making ideas tangible so feedback can improve them (IDEO.org, n.d.). Both perspectives resist a dangerous shortcut: designing based only on what the team assumes would be “reasonable.” People are not unreasonable. They are contextual. Human-centered design honors that context.</p>
            <p>In practical terms, empathy changes what teams measure and what they treat as success. It shifts focus from whether a feature exists to whether a feature supports a human goal with minimal friction. It shifts focus from whether a workflow is logically complete to whether it is cognitively manageable. It also encourages teams to define usability issues more honestly. If a user keeps making the same “mistake,” it is rarely because they are careless. It is often because the design is teaching the wrong lesson through hierarchy, labels, or interaction constraints.</p>
            <h3>What It Means to Design for People</h3>
            <p>Designing for people is designing with humility. It is accepting that perception, attention, and memory set hard constraints on usability, and that ignoring those constraints does not make them go away. It is also accepting that empathy is not a sentiment, it is a method. It shows up in user involvement, in iterative feedback loops, and in design choices that reduce effort, prevent errors, and respect how humans actually behave.</p>
            <p>ISO 9241-210 offers a durable foundation for doing this work systematically, especially in environments that need rigor and accountability. IDEO's Field Guide offers the creative posture needed to learn from people, prototype quickly, and stay flexible when the problem is not yet fully understood. The four UX laws give everyday design decisions a psychological backbone, explaining why familiar patterns matter, why target size matters, why choice overload matters, and why chunking matters.</p>
            <p>When those pieces come together, “design for people” stops being a nice idea and becomes a practical design standard: build from real context, guide attention with intentional hierarchy, reduce cognitive and physical effort, and keep learning from the humans on the other side of the screen.</p>
         <footer class="article-footer">
            <h3>Sources</h3>
            <ol>
               <li>
                  International Organization for Standardization. (2019).
                  <em>ISO 9241-210:2019. Ergonomics of human-system interaction – Part 210: Human-centred design for interactive systems</em>.
                  <a href="https://www.iso.org/standard/77520.html">
                  https://www.iso.org/standard/77520.html
                  </a>
               </li>
               <li>
                  IDEO.org. (2015).
                  <em>The field guide to human-centered design</em>.
                  <a href="https://d1r3w4d5z5a88i.cloudfront.net/assets/guide/Field%20Guide%20to%20Human-Centered%20Design_IDEOorg_English-0f60d33bce6b870e7d80f9cc1642c8e7.pdf">
                  https://d1r3w4d5z5a88i.cloudfront.net/assets/guide/Field%20Guide%20to%20Human-Centered%20Design_IDEOorg_English.pdf
                  </a>
               </li>
               <li>
                  Chung, E. (2023, June 22).
                  <em>Jakob’s Law: Creating familiar and user-centric interfaces</em>.
                  LogRocket.
                  <a href="https://blog.logrocket.com/ux-design/jakobs-law-creating-user-centric-interfaces">
                  https://blog.logrocket.com/ux-design/jakobs-law-creating-user-centric-interfaces
                  </a>
               </li>
               <li>
                  Budiu, R. (2022, July 31).
                  <em>Fitts’s Law and its applications in UX</em>.
                  Nielsen Norman Group.
                  <a href="https://www.nngroup.com/articles/fitts-law/">
                  https://www.nngroup.com/articles/fitts-law/
                  </a>
               </li>
               <li>
                  Interaction Design Foundation. (2016, June 29).
                  <em>What is Hick’s Law?</em>
                  <a href="https://www.interaction-design.org/literature/topics/hick-s-law">
                  https://www.interaction-design.org/literature/topics/hick-s-law
                  </a>
               </li>
               <li>
                  Uzegbu, C. (2024, November 26).
                  <em>How can Miller’s Law make UX better?</em>
                  LogRocket.
                  <a href="https://blog.logrocket.com/ux-design/millers-law-ux-design">
                  https://blog.logrocket.com/ux-design/millers-law-ux-design
                  </a>
               </li>
            </ol>
         </footer>
         </article>
         <!-- Module 2.2 Blog Post Starts here -->

         <!-- Module 2.3 Blog Post Starts here -->

         <!-- Module 3.1 Blog Post Starts here -->

         <!-- Module 3.2 Blog Post Starts here -->

      </main>
<!-- Page Footer  -->
      <footer class="page-footer">
       <p>Copyright &copy; 2025</p>
      </footer>
   </body>
</html>