<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link href="css/styles.css" rel="stylesheet">
      <title>Eman Al Mayahi| Portfolio</title>
   </head>
   <body>
<!-- Page Header  -->
      <header class="page-header">
         <h1>Portfolio</h1>
      </header>
<!-- Main Content Area  -->
      <main>
         
         <article>
            <header class="article-header"> 
               <h2>Module 1.1 Blog Post</h2>
            </header>
            <h3>Systems Thinking in Digital Environments: Moving Beyond Linear Approaches </h3>
            <p>As digital systems grow in scale, connectivity, and societal impact, traditional linear approaches to problem solving are increasingly inadequate. Modern digital environments such as cloud platforms, enterprise information systems, smart infrastructure, and healthcare technologies are not isolated tools. They are complex systems composed of interdependent components, stakeholders, interfaces, and life cycles. Designing and managing such systems requires a mindset that can handle complexity, uncertainty, and change. This is where systems thinking becomes essential.
              </p><p> Systems thinking is a foundational concept in systems engineering and is central to the principles outlined in Systems Engineering Demystified by Jon Holt. Rather than focusing on individual components in isolation, systems thinking emphasizes understanding relationships, interactions, and behavior across the entire system (Holt, 2019). This post defines systems thinking in my own words, contrasts it with traditional linear thinking, and explains why a model-based approach is particularly effective for designing complex digital systems.
            </p>
            <h3>Defining Systems Thinking</h3>
            <p>In my own words, systems thinking is a holistic way of understanding how parts of a system interact to produce outcomes that cannot be explained by individual components alone. It focuses on connections, feedback loops, dependencies, and context rather than isolated cause and effect relationships. Systems thinking recognizes that systems behave as integrated wholes and that changes in one area often create ripple effects elsewhere.
               </p><p>Holt explains that a system is not simply a collection of elements, but a structured hierarchy of elements connected through defined interfaces and interactions (Holt, 2019). Viewing systems in this way allows designers and engineers to understand how complexity emerges from relationships rather than from components alone. Understanding these relationships is essential to managing complexity in digital environments.
               </p><p>In practice, systems thinking helps engineers and designers anticipate unintended consequences, identify critical dependencies, understand stakeholder needs across the entire system, and manage complexity through abstraction and hierarchy. Without systems thinking, digital systems risk becoming fragmented, inefficient, or fragile.
           </p>
            <h3>How Systems Thinking Differs from Linear Thinking</h3>
            <p>Traditional linear thinking approaches problems as a sequence of steps moving from input to process to output. This approach assumes predictability, stability, and independence among system components. While linear thinking can be effective for simple or well bounded problems, it struggles when applied to complex digital systems where interactions are dynamic and outcomes are often unpredictable.
               Linear thinking tends to treat components as independent, focus on short term solutions, ignore feedback loops, and assume that changes affect only local areas of a system. In reality, digital systems rarely behave this way. For example, modifying a database structure may affect system performance, security, user experience, regulatory compliance, and long-term maintenance costs simultaneously.
            </p>
            <p> Systems thinking offers a more effective alternative by emphasizing interactions over individual components, accounting for feedback loops, considering stakeholders as integral parts of the system, and accepting uncertainty and continuous evolution. Holt emphasizes that complexity emerges primarily from interactions rather than from the number of components alone (Holt, 2019). Managing complexity through an understanding of interactions fundamentally shifts how digital systems are designed, evaluated, and maintained.
            </p>
             <h4>The Key differences between linear thinking and systems thinking can be summarized as follows:</h4>
            <ul>
               <li>Linear thinking follows predictable, step by step processes, while systems thinking focuses on interactions and feedback loops.</li>
               <li>Linear thinking addresses individual components and short term fixes, whereas systems thinking considers the whole system and long term impacts.</li>
               <li>Linear thinking underestimates complexity, while systems thinking manages complexity through controlled interactions and interfaces (Holt, 2019).</li>
               
            </ul>

            <h3>Systems, Interfaces, and Digital Complexity </h3>
            <p>.One of the most significant contributions of Systems Engineering Demystified is its emphasis on interfaces as the backbone of system behavior. Interfaces define how system elements interact and exchange information, services, or flows (Holt, 2019). In digital systems, interfaces may include application programming interfaces, user interfaces, data pipelines, or integration points with external systems.
               </p>
               <p>Poorly defined interfaces often result in fragile systems, security vulnerabilities, integration failures, and increased maintenance costs. Systems thinking encourages designers to explicitly identify, define, and manage interfaces using structured models. Doing so reduces ambiguity, improves communication among stakeholders, and ensures consistency across the entire system.
            </p>
            <h3>Why a Model Based Approach Matters</h3>
            <p>A model-based approach, commonly referred to as model-based systems engineering, is a natural extension of systems thinking. Instead of relying primarily on static documentation, this approach uses formal models to represent system structure, behavior, interfaces, and life cycles in an integrated manner.
               </p>
               <p>Holt describes model based systems engineering as a way to ensure consistency across multiple system views, allowing stakeholders to share a common understanding of the system (Holt, 2019). Models are not simply diagrams but shared representations grounded in a common ontology that all stakeholders can reference and understand.
               </p><p>IBM further explains that model-based systems engineering replaces document centric processes with digital models that support system design, analysis, verification, and validation across the entire system life cycle (IBM, n.d.). According to IBM, using shared models improves collaboration, reduces errors, and helps teams manage complexity more effectively in modern digital systems.
            </p>
            <h3>Systems Thinking and Change Over Time</h3>
            <p>Systems thinking also considers how systems evolve over time rather than focusing only on initial development. Holt emphasizes that systems should be viewed as evolving entities whose behavior and performance change as they interact with users, organizations, and environments (Holt, 2019). From a systems thinking perspective, considering the full life of a system helps designers anticipate long term impacts and avoid decisions that may solve short term problems while creating future challenges.

  
            </p>
            <h3>Systems Thinking in Practice in Digital Environments</h3>
            <p>In real world digital environments, systems thinking enables the design of scalable cloud architectures, secure data ecosystems, interoperable platforms, and sustainable technology solutions. Digital systems exist within human, organizational, and regulatory contexts, making systems thinking essential rather than optional.
               Research on systems thinking highlights how feedback loops and system dynamics shape outcomes over time, particularly in complex social and technical systems (Meadows, 2008). Ignoring these dynamics can lead to unintended consequences, even when individual components appear to function correctly.

            </p>
            <h3>Conclusion</h3>
            <p>Systems thinking provides a critical lens for understanding and designing modern digital environments that are increasingly complex, interconnected, and dynamic. Unlike linear approaches that focus on isolated components and short-term outcomes, systems thinking emphasizes relationships, interactions, interfaces, and life cycles across the entire system. As demonstrated in Systems Engineering Demystified, complexity does not arise simply from the number of elements within a system, but from the ways those elements interact over time. By adopting a systems perspective, designers and engineers are better equipped to anticipate unintended consequences, manage dependencies, and align technical decisions with broader stakeholder needs.
               </p><p>A model-based approach strengthens systems thinking by providing a shared and structured representation of the system that supports consistency, traceability, and informed decision making. As highlighted by IBM, digital models improve collaboration and reduce risk across the system life cycle by replacing fragmented documentation with a single source of truth (IBM, n.d.). As digital systems continue to evolve and integrate deeply into organizational and societal contexts, systems thinking and model-based design are no longer optional practices. They are essential foundations for building resilient, adaptable, and sustainable digital systems that can succeed over time.
               </p>

            <footer class="article-footer">
                <h3>References:</h3>
                <ol>
                  <li>Holt, J. (2019). Systems engineering demystified (2nd ed.). Packt Publishing.</li>
                    <li>IBM. (n.d.). What is model based systems engineering. IBM Think.  <a href="https://www.ibm.com/think/topics/model-based-systems-engineering">https://www.nngroup.com/articles/direct-manipulation/</a></li>
                    <li>Meadows, D. H. (2008). Thinking in systems: A primer. Chelsea Green Publishing.<a href="https://www.chelseagreen.com/product/thinking-in-systems">https://www.chelseagreen.com/product/thinking-in-systems"</a></a></li>
                
                  </ol>
            </footer>
         </article>

         
<article>
<h2>Module 1.2 Blog Post</h2>
<h3>Systems Engineering Life Cycles and Life Cycle Models in Digital Systems</h3>
<p> Systems engineers do not simply build systems and consider their work complete once a system is delivered. Instead, they guide systems through a structured life cycle that accounts for how systems are conceived, developed, operated, adapted, and eventually retired. In modern digital environments, systems rarely remain static. Software platforms, cloud services, and enterprise systems evolve continuously in response to changing technologies, user needs, and organizational priorities. For this reason, understanding systems engineering life cycles and the models used to manage them is essential.
</p>
<p>Systems Engineering Demystified emphasizes that life cycle thinking is a foundational concept in systems engineering because it encourages engineers to view systems as evolving entities rather than one-time deliverables (Holt, 2019). Different life cycle models provide different ways of organizing development and decision making over time. This blog post defines the systems development life cycle in my own words, describes the key characteristics, advantages, and potential drawbacks of linear, iterative, and incremental life cycle models, and reflects on why life cycle thinking is critical for the design, sustainability, and long-term evolution of digital systems.</p>
        
<h3>Defining the Systems Development Life Cycle</h3>
<p>In my own words, the systems development life cycle describes the structured approach used to guide a system from its initial concept through development, operation, adaptation, and eventual retirement. Rather than focusing only on building a system, the life cycle perspective emphasizes managing change over time. It provides a framework for understanding how early design decisions affect long-term performance, maintainability, cost, and sustainability.</p>
<p>Holt explains that systems engineering life cycles exist to manage complexity by organizing system evolution into understandable stages while still maintaining a holistic view of the system as a whole (Holt, 2019). This perspective aligns with ISO/IEC/IEEE 15288, which defines system life cycle processes as a coordinated set of activities that guide systems throughout their entire existence (ISO/IEC/IEEE, 2015). Importantly, the life cycle is not purely technical. It incorporates organizational, human, and operational considerations that influence how systems are used and sustained.</p>

<p>For digital systems, life cycle thinking is especially important because these systems often remain in service for many years. During that time, they are updated, expanded, integrated with other systems, and adapted to new requirements. Viewing systems through a life cycle lens helps engineers design systems that can evolve gracefully rather than becoming brittle or obsolete.</p>

<h3>The Linear Life Cycle Model</h3> 
<p>The linear life cycle model represents one of the most traditional approaches to system development. In this model, development progresses through a sequence of defined stages, with each stage largely completed before the next begins. The structure of the linear model emphasizes planning, documentation, and predictability.One of the primary advantages of the linear model is its clarity. Because each phase is clearly defined, it can be easier to manage schedules, budgets, and responsibilities. When system requirements are stable and well understood from the beginning, the linear model provides a structured path that reduces ambiguity and uncertainty (Holt, 2019).</p>
<p>However, the linear model also has notable drawbacks, particularly in digital environments. It assumes that requirements can be fully specified early in the life cycle, which is often unrealistic for complex digital systems. Once development moves into later stages, changes become costly and disruptive. This rigidity makes the linear model less suitable for systems that must adapt to evolving needs or technologies.
From a life cycle perspective, the linear model can also encourage short-term thinking. By focusing heavily on early planning and final delivery, it may underemphasize long-term operation, maintenance, and adaptation. While the linear model still has value in certain contexts, its limitations highlight why alternative life cycle models are often preferred for modern digital systems.
</p>
<h3>The Iterative Life Cycle Model</h3>
<p>The iterative life cycle model approaches system development as a series of repeated cycles rather than a single linear progression. Each iteration involves planning, development, evaluation, and refinement. This approach allows teams to learn from earlier versions of the system and incorporate feedback over time.
One of the key strengths of the iterative model is its adaptability. By revisiting design decisions in each cycle, teams can respond more effectively to uncertainty and evolving requirements. This makes the iterative model particularly well suited to digital systems, where user needs and system constraints are often discovered gradually rather than fully understood at the outset (KnowledgeHut, 2024).
</p>
<p>The iterative model also supports continuous learning and improvement. Instead of treating early design assumptions as fixed, it encourages teams to test ideas, observe system behavior, and refine solutions. This aligns closely with systems engineering principles that emphasize understanding system behavior over time rather than assuming perfect foresight (Holt, 2019).
Despite these advantages, the iterative model introduces its own challenges. Managing multiple iterations requires careful coordination and discipline. Without clear goals and boundaries, iterative development can lead to scope creep or prolonged development timelines. From a life cycle perspective, effective systems engineering oversight is necessary to ensure that repeated changes do not introduce unnecessary complexity or fragmentation (KnowledgeHut, 2024).
</p>

<h3>The Incremental Life Cycle Model</h3>
<p>The incremental life cycle model focuses on building and delivering a system in discrete parts, or increments. Each increment adds functionality while building on what has already been developed. This approach allows systems to deliver value early and evolve over time.
A major advantage of the incremental model is its balance between structure and flexibility. By delivering systems in stages, organizations can begin using portions of the system while later increments are still under development. This approach is especially useful for large or complex digital systems, where delivering everything at once would be risky or impractical (KnowledgeHut, 2024).
</p>
<p>Incremental development also supports risk management. Limiting the scope of each increment allows teams to identify issues early and reduce the impact of failures. From a life cycle perspective, incremental models emphasize continuous integration and long-term system growth rather than a single final release.
However, incremental models require careful planning to ensure that individual increments align with an overall system vision. Poorly coordinated increments can result in integration problems or technical debt. Systems engineering discipline is essential to maintain coherence across the system’s life cycle and ensure that incremental growth supports long-term goals (Holt, 2019).
</p>

<h3>Comparing Life Cycle Models</h3>
<p>Linear, iterative, and incremental models represent different ways of managing system evolution over time. The choice of life cycle model reflects how systems engineers balance predictability, flexibility, and long-term sustainability.
Linear models prioritize structure and predictability but struggle with change. Iterative models emphasize learning and adaptation but require strong coordination. Incremental models focus on phased delivery and early value but depend on effective integration strategies. No single model is universally superior. Effective systems engineering involves selecting and tailoring life cycle models to fit the system’s context, risks, and long-term objectives (ISO/IEC/IEEE, 2015; KnowledgeHut, 2024).
</p>
<h3>Why Life Cycle Thinking Matters for Digital Systems</h3>
<p>Thinking in terms of a system’s life cycle is especially important for digital systems because these systems rarely reach a true end state. Software platforms and digital services continue to evolve long after initial deployment. Decisions made early in development influence not only immediate functionality but also long-term maintainability, scalability, and sustainability.
Life cycle thinking encourages systems engineers to consider how systems will be operated, maintained, adapted, and eventually retired. International standards emphasize that sustainability and long-term effectiveness depend on managing systems across their entire life cycles rather than focusing solely on initial delivery (ISO/IEC/IEEE, 2015).</p>
<p>Holt highlights that life cycle awareness helps engineers avoid short-term solutions that create long-term problems (Holt, 2019). By considering the full life of a system, engineers can design digital systems that remain effective, adaptable, and valuable over time. This perspective is essential in environments where technology, user expectations, and organizational needs are constantly changing</p>
<h3>Conclusion</h3>
<p>Systems engineering life cycles provide a critical framework for understanding how systems evolve rather than viewing them as static products. Linear, iterative, and incremental life cycle models each offer distinct ways of managing development, change, and risk across a system’s life. Understanding their characteristics, advantages, and drawbacks enables systems engineers to make informed decisions that align with system goals and constraints.
For digital systems, life cycle thinking is not optional. Rapid technological change and continuous system evolution demand approaches that support adaptability and long-term value. By thinking in terms of a system’s life cycle, systems engineers can guide digital systems toward designs that are resilient, sustainable, and capable of evolving over time.
</p>


<footer class="article-footer">
                <h3>References:</h3>
                <ol>
                  <li>Holt, J. (2019). Systems engineering demystified (2nd ed.,Chapters 3–5.)</li>
                    <li>ISO/IEC/IEEE. (2015). ISO/IEC/IEEE 15288: Systems and software engineering — System life cycle processes.  <a href="https://www.iso.org/standard/63711.html">https://www.iso.org/standard/63711.html/</a></li>
                    <li>Knowledge Hut. (2024). Iterative vs incremental development: An overview.<a href="https://www.knowledgehut.com/blog/project-management/iterative-vs-incremental-development">https://www.knowledgehut.com/blog/project-management/iterative-vs-incremental-development"</a></a></li>
                
                  </ol>
            </footer>
</article>




<article>
<h2>Module 2.1 Blog Post</h2>
<h3>Designing for People: Applying UX Laws to Human-Centered Design</h3>
<p>Designing for people means insisting that interfaces adapt to human perception, attention, and emotion—not the other way around (Yablonski, 2024). When designers truly adopt a human-centered mindset, frameworks like ISO 9241-210, IDEO’s Field Guide, and classic UX laws become practical lenses for every design decision rather than abstract theory.</p>

<h3>Human-centered design in context</h3>

<p>Human-centered design (HCD) is an approach that keeps users’ needs, capabilities, and contexts at the center of the design process from start to finish (ISO, 2019). ISO 9241-210 defines HCD as aiming to make systems usable and useful by focusing on users, their needs, and their requirements, and by applying human factors and ergonomics throughout the life cycle (ISO, 2019). It emphasizes outcomes such as effectiveness, efficiency, satisfaction, well-being, and accessibility, as well as the mitigation of negative impacts like stress or fatigue (ISO, 2019). In practice, ISO frames human-centered design as a systematic way to align product decisions with the realities of human perception, cognition, and physical interaction.</p>
<p>Yablonski (2024) extends this idea by explicitly tying it to psychology and cognitive science. In Laws of UX, he argues that design should work with the “blueprint” of how people perceive, process, and remember information, instead of forcing people to adapt to an interface (Yablonski, 2024). This means acknowledging that users have limited attention, limited working memory, and deeply ingrained expectations shaped by other products. When designers ignore those constraints, they may ship something visually polished that still feels hard to use because it conflicts with how people naturally see and think. “Designing for people” becomes less about decoration and more about harmonizing with human limitations and strengths (Yablonski, 2024).</p>
<p>IDEO’s Field Guide to Human-Centered Design adds an explicitly empathetic and creative layer. It describes human-centered design as starting from a deep understanding of the people you are designing for, their stories, anxieties, workarounds, and aspirations (IDEO.org, 2015). That understanding is developed through interviews, observation, immersion, and co-creation, where designers listen more than they talk (IDEO.org, 2015). Empathy here is not just a feeling; it is a method for discovering how people perceive and attend to interfaces in their real lives.</p>

<h3>ISO 9241-210 and IDEO’s Field Guide</h2>
<p>ISO 9241-210 treats human-centered design as a formal standard that organizations should build into their development process. It outlines a cycle of understanding context, defining user requirements, creating solutions, and iterating based on user evaluation, with a strong emphasis on usability, ergonomics, and measurable outcomes (ISO, 2019).This ISO model represents the original human-centered design process that many later UX approaches, including data-driven methods, build upon, because its core steps capture the minimum requirements for meaningful usability work: continuous user involvement, context analysis, iterative design, and evaluation (Usability and User Experience Design, Chapter 4, pp. 81–88). The tone is procedural: it tells teams how to structure work so that human needs are considered consistently, not just during a final “usability test.”</p>
<p>IDEO’s Field Guide approaches human-centered design as a flexible, creative process driven by empathy and experimentation. It describes three loose phases, Inspiration, Ideation, and Implementation; and offers practical methods like interviews, journey mapping, and co-creation workshops to understand people and rapidly prototype ideas (IDEO.org, 2015). Instead of standards language, it focuses on mindsets such as curiosity and collaboration, encouraging teams to learn directly from users in context.
</p>
<p>Taken together, ISO and IDEO offer two complementary lenses. ISO provides the structured framework that keeps human factors on the agenda; IDEO supplies the hands-on techniques and attitudes that make empathy and iteration real in day-to-day practice (ISO, 2019; IDEO.org, 2015).
</p>

<h3>Perception, visual hierarchy, and usability</h3>
<p>Users never experience the raw information architecture of a product; they experience patterns of color, shape, contrast, and motion on a screen. Visual hierarchy is the designer’s primary tool for guiding that perception, deciding what the eye sees first, what it sees next, and what fades into background. Elements such as size, color, contrast, whitespace, alignment, and grouping can be orchestrated to signal what is important and what is peripheral. When the visual hierarchy matches users’ goals and expectations, they quickly perceive what matters and can act with minimal cognitive effort.</p>
<p>Consider a product detail page. If a promotional banner dominates the page and the “Add to Cart” button is small and low-contrast, the visual hierarchy is misaligned with the user’s primary task. Users may scan the page repeatedly, unsure where to look first, which increases cognitive load and makes the system feel cluttered. A more human-centered approach gives the product title and price clear prominence, and presents the primary action as a large, high-contrast button in a predictable location. Users perceive the intended action almost immediately, and the interface “feels” usable even before they consciously evaluate it.</p>
<p>Yablonski (2024) connects this to Gestalt principles such as proximity and similarity, which describe how people naturally group elements into patterns. When related items are close together or share a similar style, users perceive them as a unit, which reduces the mental work needed to understand the layout (Yablonski, 2024). This kind of perceptual grouping supports Miller’s Law, which suggests that people can comfortably hold around 7 ± 2 items in working memory at once. By organizing content into a small number of coherent groups, designers help users form a mental snapshot of the page that fits within their memory limits.</p>
<p>Visual hierarchy also interacts with empathy. Users bring concerns and emotions into an interface, worries about hidden fees, confusion about jargon, or fear of losing unsaved work. A human-centered design informed by research elevates information that addresses those concerns, such as transparent pricing, plain-language help, and clear status indicators. In that sense, perception is not just about what is most “important” to the business; it is about what matters most to users in the moment.</p>

<h3>Jakob’s Law: designing for expectations</h3>
<p>Jakob’s Law states that users spend most of their time on other sites and applications, so they expect your interface to behave like the ones they already know (Yablonski, 2024). When navigation, search, or checkout flows follow familiar patterns, users can reuse existing mental models instead of building new ones from scratch. Using a logo that links to the home page, predictable navigation labels, and standard iconography is therefore a human-centered choice: it respects users’ limited cognitive resources. Breaking conventions should be intentional and clearly signposted, because each departure from familiarity consumes attention and increases the risk of errors (Yablonski, 2024).</p>
<h3>Fitts’s Law: designing for movement</h3>
<p>Fitts’s Law describes how the time required to move to a target depends on the distance to that target and its size: larger, closer targets are faster and easier to hit (Yablonski, 2024). In UX design, this informs button size, spacing, and placement, especially on touch screens and for users with motor constraints. If a primary action on mobile is small, in the top corner, and surrounded by other tappable elements, users must stretch and aim carefully, increasing errors. Applying Fitts’s Law means placing key actions within easy thumb reach and making them large enough to tap without effort, reducing both physical and cognitive strain.</p>

<h3>Hick’s Law: designing for decisions</h3>
<p>Hick’s Law states that decision time increases as the number and complexity of choices grows (Yablonski, 2024). When users face too many options at once, they slow down, feel overwhelmed, or abandon the task. Designers can use Hick’s Law to manage attention by curating visible choices and structuring them into steps or categories. For example, onboarding flows can guide users through a sequence of small decisions instead of one overloaded screen, and navigation can group items into a few meaningful headings rather than a long flat list. This kind of structure treats simplification as an act of empathy rather than a limitation.</p>
<h3>Miller’s Law: designing for memory</h3>
<p>Miller’s Law suggests that people can hold about 7 ± 2 items in working memory, which directly affects how information should be structured (Yablonski, 2024). When working memory is overloaded, comprehension drops and errors increase. A site with 15 top-level navigation items forces users to hold more options than most can comfortably process, whereas five to seven categories better match typical memory limits. Likewise, breaking long forms into smaller, clearly labeled sections helps users focus on a limited set of fields at a time. In both cases, the interface takes on more of the memory burden, so users do not have to.</p>
<h3> Conclusion</h3>
<p>Jakob’s, Fitts’s, Hick’s, and Miller’s Laws form a cognitive ergonomics toolkit for human-centered design. Jakob’s Law addresses expectations and perceptual familiarity; Fitts’s Law aligns physical movement with target size and placement; Hick’s Law manages the attentional cost of decisions; and Miller’s Law frames the limits of working memory (Yablonski, 2024). Within ISO 9241-210’s structured framework and IDEO’s empathy-driven process, these laws ensure that “designing for people” is grounded in how humans actually perceive, move, decide, and remember (ISO, 2019; IDEO.org, 2015). The result is design that feels intuitive not because it is simple in some abstract sense, but because it is carefully tuned to the realities of human perception, attention, and empathy.</p>


<footer class="article-footer">
    <h3>References:</h3>
     <ol>
                   <li>IDEO.org. (2015). The field guide to human-centered design. IDEO.org.<a href=" https://www.designkit.org/resources/1.html"> https://www.designkit.org/resources/1.html/</a></li>
                    <li>ISO. (2019). ISO 9241-210:2010 – Ergonomics of human-system interaction – Human-centred design for interactive sys2590tems. International Organization for Standardization.  <a href="https://www.iso.org/standard/77520.html">https://www.iso.org/standard/77520.html</a></li>
      
                    <li>Usability and user experience design. (n.d.). Chapter 4: How to "do" usability and UX design (Excerpt).</li>
                    <li>Yablonski, J. (2024). Laws of UX: Using psychology to design better products & services (2nd ed.). O’Reilly Media. <a href="https://jonyablonski.com/articles/2024/laws-of-ux-the-2nd-edition/">https://jonyablonski.com/articles/2024/laws-of-ux-the-2nd-edition/"</a></a></li>
                
      </ol>
            </footer>
</article>



         

<article>
      <h2>Module 2.2 Blog Post</h2>
      <h3>What Makes Digital Systems Usable: Memory, Habits, and Mental Shortcuts</h3>
      <p>Digital systems feel usable when they work with the brain's natural limitations rather than fighting them. Memory holds just a handful of items at once, habits form around consistent patterns, and mental shortcuts let us predict how things work, great design leverages all three to make even complex interactions feel effortless. Usability isn't about visual polish; it's cognitive engineering that respects how humans think, remember, and act.</p>

      <h3>Memory and Mental Models in Action</h3>
      <p>Working memory, the mental scratchpad we use for active thinking, can juggle about 7 ± 2 chunks of information before overload sets in (Johnson, 2020). This explains why interfaces that dump 15 navigation options, demand memorizing multi-step processes, or scatter related controls create immediate frustration. Users don't just "get confused", their brains literally run out of short-term processing capacity.</p>
      <p>Mental models fill the gap. These are internalized maps of how systems behave, built from years of experience across thousands of interfaces. When a design matches users' expectations (hamburger menu = navigation drawer, magnifying glass = search), cognitive effort drops dramatically because users can predict outcomes without conscious analysis. When designs violate those models, like a shopping cart icon that shows product details instead of checkout, every interaction becomes high-stakes guesswork.</p>
      <p>In a dashboard project I consulted on, users repeatedly struggled with "Reports" functionality hidden behind a generic chart icon. Their mental model expected printable/exportable data under familiar labels like "Reports," "Documents," or "Export." The abstract icon forced constant memory refresh: Where did I find that last time? What does this squiggle mean again? Each visit consumed working memory that should have gone toward analysis.</p>

      <h3>Consistency and Feedback as Cognitive Scaffolding</h3>
      <p>Consistency across visual design, terminology, interaction patterns, and layout builds habits users can execute on autopilot. Primary buttons always submit forms and glow on hover. Back arrows always return to the previous state. Search icons always trigger search functionality. When consistency breaks, a "Save" button that sometimes saves drafts, sometimes publishes immediately, sometimes requires confirmation, users must abandon learned habits and decode context every single time (Usability and User Experience Design, Chapter 4, pp. 81–88).</p>
      <img src="images/krisztian-tabori-IyaNci0CyRk-unsplash.jpg" alt="book beside smartphone" height="400" width="400" style="float: right; margin-left: 15px; margin-bottom: 15px;">
      <p>Feedback closes the gulf between action and outcome, confirming whether the user's mental model remains accurate. A loading spinner during file uploads, green checkmarks after successful saves, inline error messages explaining why a form submission failed (not just "Error occurred"), these micro-confirmations prevent users from testing actions repeatedly just to verify the system behaved as expected. Silent failures, ambiguous success states, or delayed feedback create uncertainty that fills working memory with doubt: Did that work? Should I try again? Where's my data now?</p>
      <p>Consider form validation: poor design shows a generic red border with "Please fix errors" at the top. Users must hunt across fields, taxing spatial memory and attention. Great design highlights the exact problematic field with inline text like "Phone number must include area code" and a contrasting call-to-action button. The difference? One forces problem-solving, the other guides resolution.</p>

      <h3>Cognitive Load from Poor Design: Real Examples</h3>
      <p>Poor design creates extraneous cognitive load, mental work that serves no productive purpose. Three examples illustrate the damage:
      Course example (ISO 9241-210): The reading stresses context-of-use analysis to understand real user tasks and terminology, yet teams often skip it, forcing domain-specific jargon on operators. I audited a factory app where workers memorized machine codes like "X7B-42" instead of plain-language labels like "Conveyor Belt 3." With working memory already filled by production quotas, shift changes, and safety protocols, code lookup became the breaking point (Usability and User Experience Design, Chapter 4, p. 85).</p>
      <p>Personal experience: A banking app buried transaction history behind Accounts → Details → Statements with no search or recent widget. My mental model, built across a decade of banking apps, expected a prominent "Transactions" tab. Each visit taxed spatial memory retracing the three-layer path, plus decision paralysis at each layer: Does "Details" mean account summary or transactions?</p>
      <p>Industry failure: Windows 8 replaced the familiar Start menu with live tiles, obliterating 15+ years of muscle memory. Users faced choice paralysis without their spatial anchor, no bottom-left corner to muscle-memory-click for core functions. Even "simple" redesigns introduce massive complexity when they ignore learned habits (Tesler, 2018).</p>


      <h3>Tesler's Law: Complexity Must Live Somewhere</h3>
      <p>Tesler's Law of Conservation of Complexity states every system contains inherent complexity that must be handled, either by users or the system (Tesler, 2018). Usable design absorbs that complexity through intelligent defaults, automation, progressive disclosure, and error prevention. A photo editor that auto-saves every 30 seconds, suggests intelligent crops based on face detection, and hides advanced layer controls until needed obeys Tesler, the user focuses on creativity while the system handles file management. Contrast that with tools demanding manual saves, precise aspect ratio calculations, and constant layer naming; every interaction becomes infrastructure work.</p>
      <img src="images/balazs.jpg" alt="Color code book" height="400" width="400" style="float: right; margin-left: 15px; margin-bottom: 15px;" >
      
      <h3>Principles from Designing with the Mind in Mind</h3>
      <h4>Minimize Working Memory Load. </h4>
      <p>Designing with the Mind in Mind translates cognitive psychology into practical guidance for interface design, with several principles directly shaping usability outcomes (Johnson, 2020). Two principles are especially relevant to how digital systems reduce cognitive load and support user behavior.</p>
      <h4>Recognition Over Recall .</h4>
      <p>Users perform far better when options are visible rather than hidden and must be recalled from memory. Interfaces that rely on recognition—such as dropdown menus, autocomplete fields, persistent navigation, and visible system states—reduce the mental effort required to complete tasks. In contrast, designs that force users to remember buried paths or previous actions dramatically increase cognitive load. The banking app example illustrates this failure clearly: users were required to recall a multi-step navigation path instead of recognizing a clearly labeled “Transactions” tab.</p>

      <p>Because working memory is severely limited, effective interfaces chunk information into small, meaningful groups and avoid split attention. Dashboards that attempt to display too many metrics at once force users to scan, compare, and prioritize mentally, exhausting cognitive resources before meaningful interpretation can occur. By contrast, interfaces that emphasize one or two primary actions with progressive disclosure allow users to focus on decision-making rather than navigation or recall.</p>
      <p>Across both principles, consistency plays a critical supporting role. When terminology, iconography, and interaction patterns remain stable across screens and features, users can rely on established habits instead of reevaluating each action. Consistent mappings between actions and outcomes reinforce mental models and reduce uncertainty, allowing recognition and chunking strategies to work effectively rather than being disrupted by unpredictable behavior (Johnson, 2020).</p>
      <h3>Why This Matters: Usability as Cognitive Respect</h3>
      <img src="images/ux.jpg" alt="silver macbook air on table near imac" height="400" width="400" style="float: right; margin-left: 15px; margin-bottom: 15px;">
      <p>Usable systems don't eliminate complexity; they relocate it from users to the system. Tesler's Law forces the choice: should users manually save files, calculate dimensions, and remember navigation paths, or should intelligent defaults, automation, and visible options handle that work? Johnson's principles provide the mechanism: recognition saves recall effort, consistency builds automatic habits, chunking respects memory limits.</p>
      <p>Course readings ground this in process rigor. ISO 9241-210 demands iterative evaluation against documented user contexts and requirements, ensuring designs don't merely look intuitive but actually work with human cognitive constraints (Usability and User Experience Design, Chapter 4, pp. 81–88).</p>
      <p>Great design feels invisible because it disappears into learned behavior. Users don't notice consistency, instant feedback, or perfectly chunked information; they simply accomplish goals. Poor design screams for attention at every step, turning every interaction into conscious labor. Usability is cognitive respect: honoring the brain's architecture rather than demanding users compensate for flawed interfaces.</p>

   <footer class="article-footer"> 
      <h3>References </h3>

      <p>
      <ol>
         <li>Johnson, J. (2020). Designing with the mind in mind: Simple guide to understanding user interface design guidelines (3rd ed.). Morgan Kaufmann.</li>
         <li>Tesler, L. (2018). Computer limitations and freedoms. In L. Tesler (Ed.), The law of conservation of complexity. Retrieved from <a href="https://www.nomodes.com/Conservation_of_Complexity.pdf">https://www.nomodes.com/Conservation_of_Complexity.pdf</a>
         <li>Usability and user experience design. (n.d.). Chapter 4: How to "do" usability and UX design (Excerpt). [Course Materials].</li>
         <li>Yablonski, J. (2024). Laws of UX: Using psychology to design better products & services (2nd ed.). O'Reilly Media.</li>
      </ol>
      </p>

      <h4>Image Credits</h4>
         Photo by <a href="https://unsplash.com/@ktabori">Krisztian Tabori</a> on 
         <a href="https://unsplash.com/photos/change-by-design-by-tim-brown-book-beside-smartphone-IyaNci0CyRk?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink">Unsplash</a>
         <br>

         Photo by <a href="https://unsplash.com/@balazsketyi">Balázs Kétyi</a> on 
         <a href="https://unsplash.com/photos/color-code-book-LPWl2pEVGKc">Unsplash</a>

         <br>
         Photo by <a href="https://unsplash.com/@uxstore">UX Store</a> on 
         <a href="https://unsplash.com/photos/silver-macbook-air-on-table-near-imac-jJT2r2n7lYA">Unsplash</a>
   </footer>
</article>







         <!-- Module 2.3 Blog Post Starts here -->

         <!-- Module 3.1 Blog Post Starts here -->

         <!-- Module 3.2 Blog Post Starts here -->

      </main>
<!-- Page Footer  -->
      <footer class="page-footer">
       <p>Copyright &copy; 2025</p>
      </footer>
   </body>
</html>